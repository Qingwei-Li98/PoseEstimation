{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7644fa-76ac-4a04-a3b3-6712cb0b24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/ql1220/PoseEstimate/infant-3d-pose-estimation/core\n",
      "/homes/ql1220/PoseEstimate/infant-3d-pose-estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/spacepy/time.py:2294: UserWarning: Leapseconds may be out of date. Use spacepy.toolbox.update(leapsecs=True)\n",
      "  warnings.warn('Leapseconds may be out of date.'\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:570: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:594: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:598: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:615: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:620: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:109: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "curPath = os.path.abspath(os.path.dirname(\"sequential_model.py\"))\n",
    "print(curPath)\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "print(rootPath)\n",
    "sys.path.append(rootPath)\n",
    "sys.path.append(curPath)\n",
    "import torch\n",
    "from utils import datasets as ds\n",
    "from utils.transforms import SpatialTransformer, CameraTransform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import sequential_model\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5212bf8-0047-40ca-bc4c-ca98ebe01dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "activities = ['directions']\n",
    "actors=['S%d' % i for i in [1]]\n",
    "trans=transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "# root='/vol/biodata/data/h36m/training'\n",
    "root='/vol/biodata/data/h36m/training'\n",
    "pose_root='/vol/biodata/data/h36m/h36m_poses/d2'\n",
    "h=ds.Human36M(root,pose_root,activities=activities, actors=actors,sequence_len=20,random_seed=2,transforms=trans, is_train=True, subsampled_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3281d6d-c7ff-48ae-8d35-8ea304ea13fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20, 256, 256]) torch.Size([3, 256, 256]) torch.Size([16, 2, 20])\n",
      "torch.Size([16, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "pose3d_root='/vol/biodata/data/h36m/h36m_poses/d3'\n",
    "pose3d=ds.Human36MPose(pose3d_root,h.get_sequences())\n",
    "a,b,c=h.get_single(h.sequences[0])\n",
    "print(a.size(),b.size(),c.size())\n",
    "p1=pose3d.get_single(h.sequences[0])\n",
    "print(p1.size())\n",
    "poseloader = DataLoader(pose3d,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecedc650-05ee-4455-aad0-c8820242e161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1 0 (6, 1) GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.device_count(),torch.cuda.current_device(),torch.cuda.get_device_capability(device),  torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f003ff4-8d64-4da7-9e31-ed540be55028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model=sequential_model.ForwardKinematics(h,pose3d)\n",
    "logdir='/vol/bitbucket/ql1220/out/log_test1'\n",
    "checkdir='/vol/bitbucket/ql1220/out/check_test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec8a4c6-7cac-4a41-8dd0-92f45e4f7ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "epoch: 1\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "epoch: 2\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "epoch: 3\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "epoch: 4\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n"
     ]
    }
   ],
   "source": [
    "model.train(1, 5, logdir, checkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35963a0b-b8d0-4094-841d-3968b52701f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6602bd58-5211-42a0-9af6-684b50ac4db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "len_seq=20\n",
    "dataloader = DataLoader(h, batch_size, shuffle=True, drop_last=True, num_workers=8)\n",
    "def draw(dataloader,batch_size,model,len_seq):\n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        for batch in dataloader:\n",
    "            frames, frame2, preds2d = batch\n",
    "            frames, frame2, preds2d = frames.to(model.device), frame2.to(model.device), preds2d.to(model.device)\n",
    "            preds2d = model.normalize(preds2d).float()\n",
    "            preds2d1=(preds2d+1)*32\n",
    "            preds2d1=preds2d1.permute(0, 3, 1, 2).reshape(-1, 16, 2)\n",
    "            heatmaps = model.transformer(preds2d1.flip(-1))\n",
    "            heatmaps = model.upsample(heatmaps)\n",
    "\n",
    "            # convert batch*T, ch, h, w to batch, ch, h, w, T for visualization\n",
    "\n",
    "            heatmaps1 = heatmaps.view(batch_size, len_seq, 16, 256, 256).permute(0, 2, 3, 4, 1)\n",
    "            heatmap_grid = model.show_sequence_images(heatmaps1.sum(1, keepdims=True).detach())\n",
    "            plt.figure(i+1)\n",
    "            plt.imshow(heatmap_grid.permute(1,2,0).cpu())\n",
    "            i=i+1\n",
    "            if i>5:\n",
    "                break\n",
    "        plt.show()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a760c50f-675d-42c1-9bd8-ac78c3a695d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4082a5da414a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/vol/bitbucket/ql1220/out/check_test1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequential_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForwardKinematics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpose3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PoseEstimate/infant-3d-pose-estimation/core/sequential_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, pose_dataset)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoseRegressor2d1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_joints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         self.motion_discriminator_network = MotionDiscriminator(rnn_size=512, input_size=16*3, num_layers=1, output_size=1,\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/ql1220/envs/pose_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "logdir='/vol/bitbucket/ql1220/out/log_test1'\n",
    "checkdir='/vol/bitbucket/ql1220/out/check_test1'\n",
    "torch.cuda.empty_cache()\n",
    "model_test=sequential_model.ForwardKinematics(h,pose3d)\n",
    "model_test.train(1,1,logdir,checkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723d672d-2c5e-4751-97f1-5e8056fa8887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Human36MPose(Dataset):\n",
    "    def __init__(self,root,sequences, sequence_len=20):\n",
    "        self.root=root\n",
    "        self.sequences=sequences\n",
    "        self.seq_len=sequence_len\n",
    "        \n",
    "    def get_single(self,sequence):\n",
    "        pose_folder = os.path.join(self.root, sequence['actor'], sequence['activity_sequence'])\n",
    "        pose_name='/3d_pose_'\n",
    "        poses=[]\n",
    "        for i in sequence['frames']:\n",
    "            pose=np.load(pose_folder+pose_name+str(i-1)+'.npy')\n",
    "            poses.append(pose)\n",
    "        pose_array = np.array(poses)\n",
    "        pose = pose_array[:,joints,:]#(20, 16, 3)\n",
    "        pose = self.align(pose)\n",
    "        first = pose[0]\n",
    "        pelvis = first[0] + (first[1] - first[0]) / 2\n",
    "        pose -= pelvis\n",
    "        pose = self.normalize(pose)\n",
    "        pose_tensor = torch.FloatTensor(pose)\n",
    "        pose_tensor = pose_tensor.permute(1,2,0)\n",
    "        \n",
    "        return pose_tensor\n",
    "    \n",
    "    def align(self, sequence):\n",
    "        \"\"\"remove y component of hip line,\n",
    "        align pelvis-neck line with z axis\"\"\"\n",
    "        points=sequence[0]\n",
    "        pelvis = points[0] + (points[1] - points[0]) / 2\n",
    "        neck = points[2] + (points[3] - points[2]) / 2\n",
    "        pelvis_neck_line = neck - pelvis\n",
    "        # pelvis neck\n",
    "        rot_axis1 = np.array([0, -1, 0])\n",
    "        angle = self.get_angle(pelvis_neck_line, rot_axis1)\n",
    "        cross_prod = np.cross(pelvis_neck_line, rot_axis1)\n",
    "        cross_prod /= np.linalg.norm(cross_prod)\n",
    "        R1 = R.from_rotvec(angle * cross_prod)\n",
    "        for i in range(len(sequence)):\n",
    "            sequence[i] = R1.apply(sequence[i])\n",
    "        # hip\n",
    "        points=sequence[0]\n",
    "        hip_line = points[0] - points[1]\n",
    "        rot_axis2 = np.array([-1, 0])\n",
    "        indices = np.array([0, 2])\n",
    "        angle = self.get_angle(hip_line[indices], rot_axis2)\n",
    "        R2 = R.from_rotvec(np.array([0, angle, 0]))\n",
    "        for i in range(len(sequence)):\n",
    "            sequence[i] = R2.apply(sequence[i])\n",
    "\n",
    "        rot = R.from_rotvec(np.array([0,0, np.pi]))\n",
    "        for i in range(len(sequence)):\n",
    "            sequence[i] = rot.apply(sequence[i])\n",
    "\n",
    "        return sequence\n",
    "    \n",
    "    def normalize(self, points):\n",
    "        first = points[0]\n",
    "        # normalize to unit cube -1 to 1\n",
    "        max_ = np.abs(first.max())\n",
    "        min_ = np.abs(first.min())\n",
    "        if max_ >= min_:\n",
    "            points /= max_\n",
    "        else:\n",
    "            points /= min_\n",
    "        return points\n",
    "    \n",
    "    def get_angle(self,vec1, vec2):\n",
    "        inv = vec1 @ vec2 / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        return np.arccos(inv)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        seq=self.sequences[index]\n",
    "        return  self.get_single(seq)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.sequences:\n",
    "            return len(self.sequences)\n",
    "        else:\n",
    "            raise(RuntimeError(\"Dataset is empty!\"))\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d6abb-394b-434e-affd-c5462be3475b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
